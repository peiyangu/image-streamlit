{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a845e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cognitiveservices-vision-computervision\n",
      "  Downloading azure_cognitiveservices_vision_computervision-0.9.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting azure-common~=1.1\n",
      "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
      "Collecting msrest>=0.5.0\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 4.7 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 5.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Users/hiratayuuki/opt/anaconda3/lib/python3.8/site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2021.10.8)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: requests~=2.16 in /Users/hiratayuuki/opt/anaconda3/lib/python3.8/site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.26.0)\n",
      "Requirement already satisfied: six in /Users/hiratayuuki/opt/anaconda3/lib/python3.8/site-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hiratayuuki/opt/anaconda3/lib/python3.8/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/hiratayuuki/opt/anaconda3/lib/python3.8/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/hiratayuuki/opt/anaconda3/lib/python3.8/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.0.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, isodate, msrest, azure-common, azure-cognitiveservices-vision-computervision\n",
      "Successfully installed azure-cognitiveservices-vision-computervision-0.9.0 azure-common-1.1.27 isodate-0.6.0 msrest-0.6.21 oauthlib-3.1.1 requests-oauthlib-1.3.0\n",
      "Requirement already satisfied: pillow in /Users/hiratayuuki/opt/anaconda3/lib/python3.8/site-packages (8.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade azure-cognitiveservices-vision-computervision\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f15b0a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c72a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = \"590cfd151e034cdba7f711cee3d7da05\"\n",
    "ENDPOINT = \"https://20211204hirata.cognitiveservices.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ed46ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "computervision_client = ComputerVisionClient(ENDPOINT, CognitiveServicesCredentials(KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51445ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9edacfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Describe an image - remote =====\n",
      "Description of remote image: \n",
      "'an ancient city with many ruins with Colosseum in the background' with confidence 33.80%\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Describe an image - remote =====\")\n",
    "# Call API\n",
    "description_results = computervision_client.describe_image(remote_image_url )\n",
    "\n",
    "# Get the captions (descriptions) from the response, with confidence level\n",
    "print(\"Description of remote image: \")\n",
    "if (len(description_results.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_results.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9307bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##　 画像カテゴリーの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be5387d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Categorize an image - remote =====\n",
      "Categories from remote image: \n",
      "'building_' with confidence 31.64%\n",
      "'others_' with confidence 0.39%\n",
      "'outdoor_' with confidence 3.91%\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Categorize an image - remote =====\")\n",
    "# Select the visual feature(s) you want.\n",
    "remote_image_features = [\"categories\"]\n",
    "# Call API with URL and features\n",
    "categorize_results_remote = computervision_client.analyze_image(remote_image_url , remote_image_features)\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Categories from remote image: \")\n",
    "if (len(categorize_results_remote.categories) == 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for category in categorize_results_remote.categories:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0d23f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "##画像タグの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a66073d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an image - remote =====\n",
      "Tags in the remote image: \n",
      "'outdoor' with confidence 99.00%\n",
      "'building' with confidence 98.81%\n",
      "'sky' with confidence 98.21%\n",
      "'stadium' with confidence 98.17%\n",
      "'ancient rome' with confidence 96.16%\n",
      "'ruins' with confidence 95.04%\n",
      "'amphitheatre' with confidence 93.99%\n",
      "'ancient roman architecture' with confidence 92.65%\n",
      "'historic site' with confidence 89.55%\n",
      "'ancient history' with confidence 89.54%\n",
      "'history' with confidence 86.72%\n",
      "'archaeological site' with confidence 84.41%\n",
      "'travel' with confidence 65.85%\n",
      "'large' with confidence 61.02%\n",
      "'city' with confidence 56.57%\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Tag an image - remote =====\")\n",
    "# Call API with remote image\n",
    "tags_result_remote = computervision_client.tag_image(remote_image_url )\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Tags in the remote image: \")\n",
    "if (len(tags_result_remote.tags) == 0):\n",
    "    print(\"No tags detected.\")\n",
    "else:\n",
    "    for tag in tags_result_remote.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bacc59e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 物体を検出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86d1421f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Objects - remote =====\n",
      "Detecting objects in remote image:\n",
      "object at location 213, 365, 85, 208\n",
      "object at location 218, 402, 179, 384\n",
      "object at location 238, 417, 298, 416\n",
      "object at location 116, 419, 60, 386\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"===== Detect Objects - remote =====\")\n",
    "# Get URL image with different objects\n",
    "remote_image_url_objects = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg\"\n",
    "# Call API with URL\n",
    "detect_objects_results_remote = computervision_client.detect_objects(remote_image_url_objects)\n",
    "\n",
    "# Print detected objects results with bounding boxes\n",
    "print(\"Detecting objects in remote image:\")\n",
    "if len(detect_objects_results_remote.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_remote.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4103f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ローカルファイルに対応"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34ead77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Objects - local =====\n",
      "Detecting objects in remote image:\n",
      "object at location 690, 1437, 620, 1439\n"
     ]
    }
   ],
   "source": [
    "local_image_path = 'sample01.jpg'\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "\n",
    "print(\"===== Detect Objects - local =====\")\n",
    "\n",
    "detect_objects_results = computervision_client.detect_objects_in_stream(local_image)\n",
    "\n",
    "# Print detected objects results with bounding boxes\n",
    "print(\"Detecting objects in remote image:\")\n",
    "if len(detect_objects_results.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfcb7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(filepath):\n",
    "    local_image = open(filepath, \"rb\")\n",
    "\n",
    "    tags_result = computervision_client.tag_image_in_stream(local_image )\n",
    "\n",
    "    tags = tags_result.tags\n",
    "    tags_name = []\n",
    "    for tag in tags:\n",
    "        tags_name.append(tag.name)\n",
    "    return tags_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "466a6255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grass',\n",
       " 'outdoor',\n",
       " 'sky',\n",
       " 'cat',\n",
       " 'small to medium-sized cats',\n",
       " 'plant',\n",
       " 'felidae',\n",
       " 'mammal',\n",
       " 'domestic cat',\n",
       " 'whiskers',\n",
       " 'animal',\n",
       " 'standing',\n",
       " 'field']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"sample01.jpg\"\n",
    "get_tags(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97804510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_objects(filepath):\n",
    "    \n",
    "    local_image = open(filepath, \"rb\")\n",
    "\n",
    "    detect_objects_results = computervision_client.detect_objects_in_stream(local_image)\n",
    "    objects = detect_objects_results.objects\n",
    "    return objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "373df433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x7fc581cefee0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'sample01.jpg'\n",
    "detect_objects(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7df654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
